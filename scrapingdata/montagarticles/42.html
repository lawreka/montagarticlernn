<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
	  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <title>Neural Network Nightmare Fuel</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta property="og:image" content="/assets/images/MONTAGissue3banner.jpg?v=f601cd1944" />
	  <link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico">
     <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Martel+Sans:300" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="/assets/libs/fonts/ds-digital/ds-digital.css?v=f601cd1944" />
    <link rel="stylesheet" type="text/css" href="/assets/css/gatnom.css?v=f601cd1944">
    <link rel="stylesheet" type="text/css" href="/assets/css/gatnommobile.css?v=f601cd1944">
    <link rel="stylesheet" type="text/css" href="/assets/css/gatnombigh.css?v=f601cd1944">
	  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="canonical" href="https://www.montag.wtf/neural-network-nightmare-fuel/" />
    <meta name="referrer" content="no-referrer-when-downgrade" />
    <link rel="amphtml" href="https://www.montag.wtf/neural-network-nightmare-fuel/amp/" />
    
    <meta property="og:site_name" content="MONTAG" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="Neural Network Nightmare Fuel" />
    <meta property="og:description" content="Kathryn goes Deep Dream deep on images generated by neural networks, from style transfer to generative cats, and the results are not always pretty. " />
    <meta property="og:url" content="https://www.montag.wtf/neural-network-nightmare-fuel/" />
    <meta property="og:image" content="https://www.montag.wtf/content/images/2017/09/catglitch.gif" />
    <meta property="article:published_time" content="2017-09-04T15:08:55.000Z" />
    <meta property="article:modified_time" content="2018-02-19T15:11:03.000Z" />
    <meta property="article:tag" content="Neural Networks" />
    <meta property="article:tag" content="Issue 3" />
    
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Neural Network Nightmare Fuel" />
    <meta name="twitter:description" content="Kathryn goes Deep Dream deep on images generated by neural networks, from style transfer to generative cats, and the results are not always pretty. " />
    <meta name="twitter:url" content="https://www.montag.wtf/neural-network-nightmare-fuel/" />
    <meta name="twitter:image" content="https://www.montag.wtf/content/images/2017/09/catglitch.gif" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Kathryn Lawrence" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="Neural Networks, Issue 3" />
    <meta property="og:image:width" content="1920" />
    <meta property="og:image:height" content="960" />
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "MONTAG",
        "logo": {
            "@type": "ImageObject",
            "url": "https://www.montag.wtf/favicon.ico",
            "width": 60,
            "height": 60
        }
    },
    "author": {
        "@type": "Person",
        "name": "Kathryn Lawrence",
        "url": "https://www.montag.wtf/author/kathryn/",
        "sameAs": [
            "http://kathrynisabelle.com"
        ]
    },
    "headline": "Neural Network Nightmare Fuel",
    "url": "https://www.montag.wtf/neural-network-nightmare-fuel/",
    "datePublished": "2017-09-04T15:08:55.000Z",
    "dateModified": "2018-02-19T15:11:03.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://www.montag.wtf/content/images/2017/09/catglitch.gif",
        "width": 1920,
        "height": 960
    },
    "keywords": "Neural Networks, Issue 3",
    "description": "Kathryn goes Deep Dream deep on images generated by neural networks, from style transfer to generative cats, and the results are not always pretty. ",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://www.montag.wtf/"
    }
}
    </script>

    <script src="/public/ghost-sdk.min.js?v=f601cd1944"></script>
<script>
ghost.init({
	clientId: "ghost-frontend",
	clientSecret: "498f7bf5166f"
});
</script>
    <meta name="generator" content="Ghost 2.22" />
    <link rel="alternate" type="application/rss+xml" title="MONTAG" href="https://www.montag.wtf/rss/" />
    <style>
    .post-content-wrapper a
    {color: #0eabf5;}
</style>
<meta property=“fb:pages” content=“703295639781459" />

<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T29RQFX');</script>
<!-- End Google Tag Manager -->
                                                                                                                                                                
<script data-obct type="text/javascript">
/** DO NOT MODIFY THIS CODE**/
!function(_window, _document) {
var OB_ADV_ID='00e4a6151bc6bb049fbaff92bf8d399ae0';
if (_window.obApi) { return; }
var api = _window.obApi = function() {api.dispatch ? api.dispatch.apply(api, arguments) : api.queue.push(arguments);};api.version = '1.0';api.loaded = true;api.marketerId = OB_ADV_ID;api.queue = [];var tag = _document.createElement('script');tag.async = true;tag.src = '//amplify.outbrain.com/cp/obtp.js';tag.type = 'text/javascript';var script = _document.getElementsByTagName('script')[0];script.parentNode.insertBefore(tag, script);}(window, document);
obApi('track', 'PAGE_VIEW');
</script>
    <style>
    .pullquote{
      font-size: 1.5em;
      margin-left: 1em;
      margin-bottom: 1em;
      border-left: 2px solid #ffffff;
      padding-left: 0.5em;
    }
    .embed{
      max-width: 100%;
      text-align: center;
      padding-top: 1em;
      padding-bottom: 1em;
    }
    /*Issues pages*/
    .issuespic{
      display: inline-block;
      vertical-align: top;
      width: 48%;
      padding: 0;
    }
    .issues-image{
      width: 96%;
      height: auto;
      padding: 2%;
    }
    .issuestext{
      display: inline-block;
      vertical-align: top;
      width: 48%;
      padding-top: 2%;
    }
    @media (max-width:992px){
      .issuespic{
        display: block;
        width: 100%;
      }
      .issues-image{
        width: 100%;
        height: auto;
        padding: 0;
      }
      .issuestext{
        display: block;
        width: 100%;
        padding-top: 2%;
        padding-bottom: 5%;
      }
    }
    </style>
  </head>
  <div id="content-wrapper">
    <!-- MONTAG logo and Grover logo stuck to top of page -->
<div id="sticky-logobar">
  <div id="sticky-montag-logo">
    <a href="https://www.montag.wtf" alt="montag.wtf">
      <img class="montaglogo" src=/assets/images/blackmontag.png?v=f601cd1944>
    </a>
  </div>
  <div id="sticky-grover-logo">
    <a href="https://www.grover.com/" alt="grover.com">
      <img class="groverlogo" src=/assets/images/blackgroverlogo.png?v=f601cd1944>
    </a>
  </div>
</div>
  <div class="postpage-post-wrapper">
    <div class="post-info-wrapper">
      <div class="post-info">
        <div class="post-image">
          <img src="/content/images/2017/09/catglitch.gif" class="postimage"/>
        </div>
        <div class="authordatewrap">
          <div class="post-author">
              <a href="/author/kathryn/">Kathryn Lawrence</a>
          </div>
          <div class="post-date">
            September 04, 2017
          </div>
        </div>
        <div class="post-title">
          Neural Network Nightmare Fuel
        </div>
        <div class="post-tags">
          <ul style="font-size: 0.8em;"> TAGS:
              <li><a href="/tag/neural-networks">Neural Networks</a></li>
              <li><a href="/tag/issue-3">Issue 3</a></li>
          </ul>
        </div>
      </div>
    </div>
    <div class="post-content-wrapper">
      <div class="post-content">
        <div class="content-text">
          <p><em>Warning: this post contains images that may be disturbing, particularly to the trypophobic and those averse to badly drawn cats</em></p>
<p>Last week in <a href="http://www.montag.wtf/fun-with-neural-networks/" target="_blank">Fun With Neural Networks</a> we covered the delightful neural network projects of <a href="https://twitter.com/janellecshane?lang=en" target="_blank">Janelle Shane</a>, who wants to &quot;<a href="https://twitter.com/JanelleCShane/status/862873117340819457" target="_blank">Char-rnn ALL THE THINGS</a>&quot; with often hilarious results.</p>
<p>The <em>things</em> she tends towards, though, are largely text-based data. This week, we're going deeper. Deep Dream deep.</p>
<h1 id="divedivedive">Dive, dive, dive!</h1>
<p>Released in July of 2015, Google's <a href="https://deepdreamgenerator.com/" target="_blank">Deep Dream</a> computer vision program delighted and horrified humanity with its image manipulation capabilities. Using what has been dubbed &quot;<a href="https://en.wikipedia.org/wiki/DeepDream" target="_blank">algorithmic pareidolia</a>,&quot; Deep Dream uses its neural network programming (that's the algorithmic part) to classify and manipulate images in a way that it recognizes; the pareidolia part comes from its similarity to the human psychological phenomenon of seeing human faces on non-human objects (<a href="https://www.reddit.com/r/Pareidolia/" target="_blank">/r/pareidolia</a> always has a fresh supply of examples, but you can probably find one in the objects around you right now!)</p>
<p>But Deep Dream doesn't see faces... at least not the way humans do. While some of the resulting images are charmingly abstract and would make a lovely psychedelic print:</p>
<div class="embed">
<img src="http://i.telegraph.co.uk/multimedia/archive/03370/magic_3370394k.jpg">
<p>Deep Dream image from Google via <a href="http://www.telegraph.co.uk/technology/google/11730050/deep-dream-best-images.html?frame=3370394" target="_blank">The Telegraph</a></p>
</div>
<p>Others, like this GIF that made it to the front page of Reddit, are pure bad trip:</p>
<div class="embed">
<iframe src="https://giphy.com/embed/dE5VNLfHyf79K" width="480" height="395" frameBorder="0" class="giphy-embed" allowFullScreen></iframe><p><a href="https://giphy.com/gifs/dream-google-code-dE5VNLfHyf79K">via GIPHY</a></p>
</div>
<p>The network's propensity for finding animal faces and eyes is a result of its training data, but some have theorized that the hallucinogenic resemblance of its output may be evidence of neural networks' impending ability to replicate human brain complexity (or at least some <a href="https://www.theatlantic.com/technology/archive/2015/09/robots-hallucinate-dream/403498/" target="_blank">aspects of our visual cortex</a>). If you're interested in even wilder theories about what Deep Dream could evolve into, MONTAG published a short fiction entitled <a href="http://www.montag.wtf/deep-dream/" target="_blank">Deep Awakening</a> on this very subject.</p>
<p>Even Google admits on the Deep Dream site that use of the algorithm has primarily become a new medium for creating psychedelic and abstract art. A recent example is the music video for Foster the People's &quot;Doing It For The Money.&quot; Hold on to your pumped up kicks as you watch what is a fairly standard pop video (the band in a room, the silhouette of a woman, shots of driving, someone running somewhere, for some reason) get a little extra flavor from sticking a square of circuit board-printed blotter paper under its tongue:</p>
<div class="embed">
<iframe width="560" height="315" src="https://www.youtube.com/embed/dJ1VorN9Cl0" frameborder="0" allowfullscreen></iframe>
</div>
<h1 id="stealherstyle">Steal Her Style!</h1>
<p>Less disturbing and surreal, the Deep Dream network's cousin, Deep Style, can perform style transfer, where it uses the network's knowledge of painting styles to combine two images, overlaying the textures, shapes, and colors of one, onto the composition of another (check out the <a href="https://deepdreamgenerator.com/feed" target="_blank">Deep Dream feed</a> for the source images as well as the results):</p>
<div class="embed">
<img src="https://s3-us-west-1.amazonaws.com/ddg-dream/dream_v8ivmjg4k3x.jpg" target="_blank">
<p>Candy hearts and citrus fruits combined by <a href="https://deepdreamgenerator.com/u/darko" target="_blank">Conrad Roberts</a></p>
</div>
<div class="embed">
<img src="https://s3-us-west-1.amazonaws.com/ddg-dream/dream_lmjlazha7zv.jpg" target="_blank">
<p>A house and clouds combined by <a href="https://deepdreamgenerator.com/u/404750" target="_blank">Don Eidson</a></p>
</div>
<p>Style transfer was originally developed by a research team from the University of Tubingen in Germany, who released <a href="https://arxiv.org/abs/1508.06576" target="_blank">A Neural Algorithm of Artistic Style</a>, but you can now see style transfer algorithms everywhere: Google, Adobe, Facebook, and tons of standalone apps like <a href="https://prisma-ai.com/" target="_blank">Prisma</a> use style transfer to make your photos look they were painted by Van Gogh or Picasso.</p>
<p>One neural network-driven style transfer art project recently went viral on Twitter: dinosaurs and flowers by Chris Rodley (<a href="https://twitter.com/chrisrodley?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor" target="_blank">@chrisrodley</a>) used the web app <a href="https://deepart.io/page/about/" target="_blank">DeepArt.io</a> to combine books of prehistoric beasts with flowers and 19th-century engravings of fruit:</p>
<div class="embed">
<img src="https://remember1987.files.wordpress.com/2017/06/dinoflowers.jpg?w=914&h=347">
<p>via <a href="https://chrisrodley.com/2017/06/19/dinosaur-flowers/" target="_blank">Chris Rodley</a></p>
</div>
<p>Due to the crazy amount of interest the internet expressed in these floral monstrosities, Chris Rodley hosted the answers to some frequently asked questions on his <a href="https://chrisrodley.com/2017/06/19/dinosaur-flowers/" target="_blank">blog</a> about how to do it yourself.</p>
<p>If you want to get really deep into the code and set up your own neural networks, there are open source projects <a href="https://github.com/luanfujun/deep-photo-styletransfer?utm_content=buffer39dd6&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer" target="_blank">available on Github</a> that you can use to start, or try a web app like DeepArt.io or <a href="http://www.ostagram.ru/static_pages/lenta?last_days=30&locale=en" target="_blank">Ostagram</a>.</p>
<p>Unlike a simple photo filter, web apps like these let you enter both images: the one you want to apply style to and the one to take the style from. It's a very different process when the user chooses both parts of the equation (as opposed to when we let the neural network impose its own idea of a style) because, as we'll see in later examples of neural network processed images, the source material really matters.</p>
<h1 id="neuralnetworkshaveaveryvaguesenseofwhatcatsaremadeof">Neural networks have a very vague sense of what cats are made of</h1>
<p>Let's take cats as a wild example. Imagine a neural network exists that wants to turn anything you feed into it into what it thinks a cat is.</p>
<p>First, of course, the network has to have some definition of what a cat is, which is easier said than done.</p>
<p>Here are several projects illustrating the fact that sometimes neural networks are very bad at finding out exactly what things are.</p>
<p><a href="http://imgur.com/a/K4RWn" target="_blank">This image set</a>, which circulated on the internet as &quot;Adversarial images for machine learning,&quot; was attributed to <a href="https://twitter.com/teenybiscuit" target="_blank">@teenybiscuit</a>. These are problems that even humans might not figure out at first glance: is that a chihuahua? Or a blueberry muffin?</p>
<div class="embed">
<img src="http://i.imgur.com/b2iqPkY.jpg">
<p>Chihuahua or muffin via <a href="http://imgur.com/a/K4RWn" target="_blank">Imgur</a></p>
</div>
<p>But it turns out that neural networks can be tricked even more easily than human eyes, as explained in this article by Julie Evans: <a href="https://codewords.recurse.com/issues/five/why-do-neural-networks-think-a-panda-is-a-vulture" target="_blank">&quot;How to trick a neural network into thinking a panda is a vulture.&quot;</a> Without getting deep into the math, these mistakes are incredibly easy for neural networks to make.</p>
<p><a href="http://samim.io/" target="_blank">Sam Winiger</a>, who also created neural networks that wrote <a href="https://www.youtube.com/watch?v=-OodHtJ1saY" target="_blank">in the style of a TED Talk</a>, shared his attempts at &quot;computational comedy&quot; by having a neural network create image captions that are occasionally hilariously wrong:</p>
<div class="embed">
<img src="https://cdn-images-1.medium.com/max/600/1*MdT7_d9nM9mE6ALC2rdbXA.jpeg">
<p>via <a href="https://medium.com/@samim/generating-captions-c31f00e8396e" target="_blank">Medium</a></p>
</div>
<p>The pix2pix image demo <a href="https://affinelayer.com/pixsrv/#edges2cats" target="_blank">Edges 2 Cats</a> uses a Generative Adversarial Network (or GAN) which is another type of neural network. In this particular demo, it has been trained on 2000 stock photos of cats, and will try to transform any line drawing into a cat-like object.</p>
<div class="embed">
<img src="https://montag.wtf/content/images/2017/09/Screen-Shot-2017-09-04-at-16.06.14.png">
<p>Pix2pix example of <a href="https://affinelayer.com/pixsrv/#edges2cats" target="_blank">edges2cats</a></p>
</div>
<div class="embed">
<img src="https://montag.wtf/content/images/2017/09/Screen-Shot-2017-09-04-at-16.10.36.png">
<p>Flagrant abuse of <a href="https://affinelayer.com/pixsrv/#edges2cats" target="_blank">edges2cats</a></p>
</div>
<p>As you can see, misuse of this tool creates fuzz-covered balls of weird that resemble animals just enough to be disturbing.</p>
<p>And it's even worse when pix2pix tries to make people.</p>
<p>As we saw in Deep Dream's manipulations, we've blown through the uncanny valley with neural network image processing and into the Uncanny Mariana Trench.</p>
<p><a href="https://motherboard.vice.com/en_us/article/8x9nmz/nightmare-hellface-generator-is-cutting-edge-machine-learning" target="_blank">Motherboard</a> covered the use of the same pix2pix algorithm in a Dutch photo-generation tool that was trained on many images of a single person and has since been <a href="https://dekennisvannu.nl/site/artikel/Fotogenerator-The-End/9232" target="_blank">shut down</a> after its viral popularity incurred crippling server costs:</p>
<div class="embed">
<iframe width="560" height="315" src="https://www.youtube.com/embed/pWNgq4f4jDg" frameborder="0" allowfullscreen></iframe>
</div>
<p>(To see more examples of the now-defunct fotogenerator, check out coverage by <a href="http://digg.com/2017/face-drawing-neural-network-pix2pix" target="_blank">Digg</a> and <a href="https://www.theverge.com/tldr/2017/6/6/15749754/pix2pix-auto-fill-neural-network-images-portraits" target="_blank">The Verge</a>)</p>
<p><strong>For those who are</strong> <a href="http://www.telegraph.co.uk/technology/2017/07/12/scarily-convincing-fake-video-tool-puts-words-obamas-mouth/" target="_blank"><strong>afraid</strong> that artificial intelligence-powered voice and video manipulation</a> will mean that in the future no digital artifact can by trusted, these experiments should give you hope. For now, you can tell when a neural network is generating images, because it still doesn't look quite right in the best scenarios, and in the worst cases, it's the stuff of nightmares.</p>

        </div>
        <div class="post-permalink">
          <a href="/neural-network-nightmare-fuel/">Permalink</a>
        </div>
      </div>
    </div>
  </div>
  <div class="pagination">
  <div class="pagination-right">
		<a href="/doing-the-robot/">
      Doing The Robot &rarr;
    </a>
  </div>
  <div class="pagination-left">
		 <a href="/artificial-intelligence-you-i-i-i-i-i-everything-else/">
      &larr; ARTificial Intelligence: you i i i i i everything else
    </a>
  </div>
</div>

  </div>
    <div id="footer">
  <div id="copyright">
    <span class="footertext">
      Copyright © MONTAG 2019
    </span>
  </div>
</div>
    
    <script type="text/javascript" src="/assets/js/jquery-3.3.1.slim.min.js?v=f601cd1944"></script>
    <script type="text/javascript" src="/assets/js/gatnom.js?v=f601cd1944"></script>
</html>
